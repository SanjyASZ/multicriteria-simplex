- quel est l'objet de ton travail?
- de quoi es-tu parti?
- quel est le modele du probleme aborde?
- quelles sont les principales notations?
- quels sont les objectifs atteints, ceux repoussés?


\section{A reformuler et séquencer}
Cas litigeux à traiter:
\begin{itemize}
    \item normaliser le problème (fait)
    \item le plus générique possible (fait)
    \item les combinaisons linéaires (fait)
    \item solution dégénérée (presque)
\end{itemize}
Avant de commencer toute implémentation, il serait pertinent de savoir sous quelles formes traiter les MOLP. Subséquemment, la notation et la formulation utilisées dans le livre "Multicriteria Optimization" de Matthias Ehrgott ont été reprises.

Voici un exemple extrait de la page 180.

\begin{center}
\begin{tabular}{ l c p{1pt} c }
Min     & \multicolumn{3}{l}{$-x_1 - 2x_2$} \\
Min     & \multicolumn{3}{l}{$-x_1 + 2x_3$} \\
Min     & \multicolumn{3}{l}{$x_1 - x_3$} \\

s.t.    & $x_1 + x_2 & $\leq$ & $1$\\
        & $x_2  & $\leq$ & $4$ \\
        & $x_1 -x_2 + x_3$ & $\leq$ & $4$ \\
\end{tabular}
\end{center}

Cela peut paraître contre-intuitif (des inférieur ou égal avec des Min) mais dans la formulation on a bien:

\begin{itemize}
    \item Fonction objectif: tout est en minimisation
    \item au niveau des contraintes tout est en inférieur ou égal.
\end{itemize}

Nous ramènerons donc tout MOLP (MultiObjective Linear Programm) sous cette forme dans un souci de cohérence pour la définition du problème dual.

\underline{Transformation :}
\newline
Les fonctions à maximiser deviennent des minimisation en étant multiplié par -1.

\begin{itemize}[label=\textbullet,font=\normal]
    \item Max$f(X)$ devient Min $-f(X)$
    \item Les $ h(X) >= b$ deviennent $-h(X) <= -b$
    \item Les $h(X) = b $ sont transformés en deux contraintes: \\ $h(X) <=b$ et $ -h(X) <= -b$
\end{itemize}

\underline{Exemple:}

On a le MOLP suivant:

\begin{center}
\begin{tabular}{ l c p{1pt} c }
Max     & \multicolumn{3}{l}{$3x_1 - 2x_2$} \\

Max     & \multicolumn{3}{l}{$x_1 + 2x_2$} \\

s.t.    & $ 3x_1 + 2x_2 $ & $ = $ & $ 1$

\end{tabular}
\end{center}

\smallbreak
Celui ci est équivalent à :

\begin{center}
\begin{tabular}{ l c p{1pt} c }
Min     & \multicolumn{3}{l}{$-3x_1 + 2x_2$} \\
Min     & \multicolumn{3}{l}{$-x_1 - 2x_2$} \\

s.t.    & $ 3x_1 + 2x_2 & $ \leq & $1$ \\
s.t.    & $ -3x_1 - 2x_2 & $ \leq  & $-1$
\end{tabular}
\end{center}

\smallbreak
L'utilité de cette normalisation est expédiente dans la mesure où le problème dual associé en deviendra plus facilement traitable. Notons néanmoins que cette normalisation n'interviendra qu'en tant que pré-traitement de la phase 2.

\smallbreak
Cinq informations sont donc importantes pour la représentation et la formalisation de nos MOLP.

\begin{itemize}
    \item Les coefficients des fonctions objectives (Tableau de tableau de flottants intitulé "objectiv")
    \item L'indication de minimisation ou maximisation des fonctions (tableau d'entiers intitulé "MM")
    \item Les coefficients dans les contraintes (matrice nommé "constraint")
    \item Les seconds membres (tableau de flottants nommé "b")
    \item L'indication d'inéquation ou d'égalité (tableau d'entiers intitulé "equ\_const")
\end{itemize}

Pour illustrer concrètement cette représentation, faisons un raisonnement inductif en s'aidant d'un exemple. Reprenons le MOLP suivant:

\begin{center}
\begin{tabular}{ l c p{1pt} c }
Min     & \multicolumn{3}{l}{$-x_1 - 2x_2$} \\
Min     & \multicolumn{3}{l}{$-x_1 + 2x_3$} \\
Min     & \multicolumn{3}{l}{$x_1 - x_3$} \\

s.t.    & $x_1 + x_2 & $\leq$ & $1$ \\
        & $x_2  & $\leq$ & $4$ \\
        & $x_1 -x_2 + x_3$ & $\leq$ & $4$ \\
\end{tabular}
\end{center}

On aura :
\\

\underline{Les objectifs:}\smallbreak
objectiv=[ [-1.0 , -2.0 , 0.0] , [ -1.0 , 0.0 , 2.0], [ 1.0 , 0.0 , -1.0] ]


\underline{Max ou Min:}\smallbreak
MM=[O,O,O]\\
MM[i]=0 signifie que le ième objectif est une minimisation  \\
MM[i]=1 signifie que le ième objectif est une maximisation

\underline{Matrice de contraintes:} \smallbreak
constraint=[ 1.0 1.0 0.0 ; 0.0 1.0 0.0; 1.0 -1.0 1.0]

\underline{Membre de droite:} \smallbreak
b=[1.0,2.0,4.0]

\underline{Equation ou inéquation:} \smallbreak
equ\_const=[1,1,1]\\
equ\_const[i]= 1 signifie que la ième contrainte est une inéquation inférieure ou égale \\
equ\_const[i]= 2 signifie que la ième contrainte est une inéquation supérieure ou égale \\
equ\_const[i]= 3 signifie que la ième contrainte est une égalité

\smallbreak
Si on a MM qui correspond à une suite de 0 et equ\_const qui correspond à une suite de 1 cela signifie que le format est bon et qu'on a bien que des minimisation et des inférieures ou égales.

\bigbreak
Nous avons vu dans la partie rappel que dans l'execution de la phase 1 et 2, il nous faudra résoudre 3 programmes linéaires.

Dans le premier programme linéaire de la phase 1, il s'agira simplement d'enlever les contraintes à l'égalité qui sont des combinaisons linéaires. Cela se fait très bien à l'aide des outils d'algèbre linéaire présent dans le package LinearAlgebra de Julia.
Voici le pseudo-code de "verif\_combi\_lin" qui vérifie et supprime les contraintes d'égalités linéairement dépendantes.

\begin{enumerate}
    \item Le MOLP possède t-il un \textit{feasible set}?
    \item \begin{enumerate}
            \item L' \textit{efficient set} est-il vide?
            \item Trouvons une première base non dominée
          \end{enumerate}
    \item Trouvons l'ensemble des bases efficientes (efficaces?) à partir de (b)

\end{enumerate}

\input{algo.tex}
